{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euj-_uflLaWJ"
      },
      "source": [
        "# **Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6akLy47LaWK"
      },
      "source": [
        "## **Business Context**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-vxA9-MLaWK"
      },
      "source": [
        "Workplace safety in hazardous environments like construction sites and industrial plants is crucial to prevent accidents and injuries. One of the most important safety measures is ensuring workers wear safety helmets, which protect against head injuries from falling objects and machinery. Non-compliance with helmet regulations increases the risk of serious injuries or fatalities, making effective monitoring essential, especially in large-scale operations where manual oversight is prone to errors and inefficiency.\n",
        "\n",
        "To overcome these challenges, SafeGuard Corp plans to develop an automated image analysis system capable of detecting whether workers are wearing safety helmets. This system will improve safety enforcement, ensuring compliance and reducing the risk of head injuries. By automating helmet monitoring, SafeGuard aims to enhance efficiency, scalability, and accuracy, ultimately fostering a safer work environment while minimizing human error in safety oversight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyg2gF6aLaWL"
      },
      "source": [
        "## **Objective**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgBdm07qLaWL"
      },
      "source": [
        "As a data scientist at SafeGuard Corp, you are tasked with developing an image classification model that classifies images into one of two categories:\n",
        "- **With Helmet:** Workers wearing safety helmets.\n",
        "- **Without Helmet:** Workers not wearing safety helmets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm8jkm9kLaWL"
      },
      "source": [
        "## **Data Description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plkAN0OyLaWM"
      },
      "source": [
        "The dataset consists of **631 images**, equally divided into two categories:\n",
        "\n",
        "- **With Helmet:** 311 images showing workers wearing helmets.\n",
        "- **Without Helmet:** 320 images showing workers not wearing helmets.\n",
        "\n",
        "**Dataset Characteristics:**\n",
        "- **Variations in Conditions:** Images include diverse environments such as construction sites, factories, and industrial settings, with variations in lighting, angles, and worker postures to simulate real-world conditions.\n",
        "- **Worker Activities:** Workers are depicted in different actions such as standing, using tools, or moving, ensuring robust model learning for various scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi_PxtHaCM9f"
      },
      "source": [
        "# **Installing and Importing the Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7KFLO3pMGFa"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow[and-cuda] numpy==1.25.2 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "3GTXQbMhf-Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "- After running the above cell, kindly restart the notebook kernel (for Jupyter Notebook) or runtime (for Google Colab) and run all cells sequentially from the next cell.\n",
        "\n",
        "- On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code in this notebook."
      ],
      "metadata": {
        "id": "u_sYgmQfVuWu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5f4vwto0XAx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np                                                                               # Importing numpy for Matrix Operations\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.image as mpimg                                                                              # Importing pandas to read CSV files\n",
        "import matplotlib.pyplot as plt                                                                  # Importting matplotlib for Plotting and visualizing images\n",
        "import math                                                                                      # Importing math module to perform mathematical operations\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Tensorflow modules\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator                              # Importing the ImageDataGenerator for data augmentation\n",
        "from tensorflow.keras.models import Sequential                                                   # Importing the sequential module to define a sequential model\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,BatchNormalization # Defining all the layers to build our CNN Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD                                                 # Importing the optimizers which can be used in our model\n",
        "from sklearn import preprocessing                                                                # Importing the preprocessing module to preprocess the data\n",
        "from sklearn.model_selection import train_test_split                                             # Importing train_test_split function to split the data into train and test\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16                                               # Importing confusion_matrix to plot the confusion matrix\n",
        "\n",
        "# Display images using OpenCV\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#Imports functions for evaluating the performance of machine learning models\n",
        "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score, recall_score, precision_score, classification_report\n",
        "from sklearn.metrics import mean_squared_error as mse                                                 # Importing cv2_imshow from google.patches to display images\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_Z6P5GB0pFf"
      },
      "outputs": [],
      "source": [
        "# Set the seed using keras.utils.set_random_seed. This will set:\n",
        "# 1) `numpy` seed\n",
        "# 2) backend random seed\n",
        "# 3) `python` random seed\n",
        "tf.keras.utils.set_random_seed(812)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imLbhd-DgvS7"
      },
      "source": [
        "# **Data Overview**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5POB8BZY5LZA"
      },
      "source": [
        "##Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgHh1gtjxn0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6isEG2IiPR-"
      },
      "source": [
        "# **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW10huj6-G3P"
      },
      "source": [
        "###Plot random images from each of the classes and print their corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXV0SYQIUmf1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPvYaLZwVBV-"
      },
      "source": [
        "## Checking for class imbalance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86RryQG0VFQO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOTN6HZfj2sh"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O68pNCUoyJKL"
      },
      "source": [
        "## Converting images to grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dotZUTbwyInd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzrVaz-eiOC2"
      },
      "source": [
        "### Splitting the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnxkcTh_iLU2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7xRHTbDiBmI"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOyE9HKcddXq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYpdH2ZKAEPm"
      },
      "source": [
        "# **Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lst3zQq9xwvi"
      },
      "source": [
        "##Model Evaluation Criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw2Y47jiX0D2"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5VVWhsiX2Bm"
      },
      "outputs": [],
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using statsmodels\n",
        "def model_performance_classification(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # checking which probabilities are greater than threshold\n",
        "    pred = model.predict(predictors).reshape(-1)>0.5\n",
        "\n",
        "    target = target.to_numpy().reshape(-1)\n",
        "\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred, average='weighted')  # to compute Recall\n",
        "    precision = precision_score(target, pred, average='weighted')  # to compute Precision\n",
        "    f1 = f1_score(target, pred, average='weighted')  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame({\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1 Score\": f1,},index=[0],)\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQarp_eBZHQK"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(model,predictors,target,ml=False):\n",
        "    \"\"\"\n",
        "    Function to plot the confusion matrix\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    ml: To specify if the model used is an sklearn ML model or not (True means ML model)\n",
        "    \"\"\"\n",
        "\n",
        "    # checking which probabilities are greater than threshold\n",
        "    pred = model.predict(predictors).reshape(-1)>0.5\n",
        "\n",
        "    target = target.to_numpy().reshape(-1)\n",
        "\n",
        "    # Plotting the Confusion Matrix using confusion matrix() function which is also predefined tensorflow module\n",
        "    confusion_matrix = tf.math.confusion_matrix(target,pred)\n",
        "    f, ax = plt.subplots(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        confusion_matrix,\n",
        "        annot=True,\n",
        "        linewidths=.4,\n",
        "        fmt=\"d\",\n",
        "        square=True,\n",
        "        ax=ax\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW8sb9YLhzEj"
      },
      "source": [
        "##Model 1: Simple Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GLwHU8SqxUAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cORD8xplvc1r"
      },
      "source": [
        "### Vizualizing the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-XtEiDDvPlk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLlbSZ35dGCs"
      },
      "source": [
        "## Model 2: (VGG-16 (Base))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb629HQJv4Q2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxgo96n1w96D"
      },
      "source": [
        "### Visualizing the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEug_K8yh648"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11d6WbFZaOk"
      },
      "source": [
        "## Model 3: (VGG-16 (Base + FFNN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyPTg137wotU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx2pgODjZaO4"
      },
      "source": [
        "#### Visualizing the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YeVQIidZaO4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvZIETwXZcEh"
      },
      "source": [
        "## Model 4: (VGG-16 (Base + FFNN + Data Augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-fC-MB7f9sz"
      },
      "source": [
        "- In most of the real-world case studies, it is challenging to acquire a large number of images and then train CNNs.\n",
        "- To overcome this problem, one approach we might consider is **Data Augmentation**.\n",
        "- CNNs have the property of **translational invariance**, which means they can recognise an object even if its appearance shifts translationally in some way. - Taking this attribute into account, we can augment the images using the techniques listed below\n",
        "\n",
        "    -  Horizontal Flip (should be set to True/False)\n",
        "    -  Vertical Flip (should be set to True/False)\n",
        "    -  Height Shift (should be between 0 and 1)\n",
        "    -  Width Shift (should be between 0 and 1)\n",
        "    -  Rotation (should be between 0 and 180)\n",
        "    -  Shear (should be between 0 and 1)\n",
        "    -  Zoom (should be between 0 and 1) etc.\n",
        "\n",
        "Remember, **data augmentation should not be used in the validation/test data set**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzw1oMWSwuZG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRCSl2lFZcE1"
      },
      "source": [
        "#### Visualizing the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmrUAQGVZcE1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi2j5UBzvY12"
      },
      "source": [
        "# **Model Performance Comparison and Final Model Selection**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSeJOFHtxgLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98b4v3M-9iXp"
      },
      "source": [
        "## Test Performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lw9dNlFAxkMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcwtqcC8JWW7"
      },
      "source": [
        "# **Actionable Insights & Recommendations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYNYcpxfbVfU"
      },
      "source": [
        "-\n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7BM8YUAbUa6"
      },
      "source": [
        "<font size=5 color='blue'>Power Ahead!</font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "euj-_uflLaWJ",
        "O6akLy47LaWK",
        "Kyg2gF6aLaWL",
        "Vm8jkm9kLaWL",
        "yi_PxtHaCM9f"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}