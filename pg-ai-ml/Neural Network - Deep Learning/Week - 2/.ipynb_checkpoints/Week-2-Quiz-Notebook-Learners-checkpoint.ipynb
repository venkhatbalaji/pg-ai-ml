{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35e39bb",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "This data set includes customers who have paid off their loans, who have been past due and put into collection without paying back their loan and interests, and who have paid off only after they were put in the collection. The financial product is a bullet loan that customers should pay off all of their loan debt in just one time by the end of the term, instead of an installment schedule. Of course, they could pay off earlier than their pay schedule.\n",
    "\n",
    "### Attribute information:\n",
    "\n",
    "- Loan_status: Whether a loan is paid off, in the collection, new customer yet to pay off, or paid off after the collection efforts\n",
    "\n",
    "- Principal: Basic principal loan amount at the origination\n",
    "\n",
    "- terms: Can be weekly (7 days), biweekly, and monthly payoff schedule\n",
    "\n",
    "- Age, education, gender: A customer’s basic demographic information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfeb36",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e192ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Library to encode the variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " # Library to split data\n",
    "from sklearn.model_selection import train_test_split  \n",
    "# library to import different optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "# Library to import different loss functions \n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Library to avoid the warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# importing keras library\n",
    "from tensorflow import keras\n",
    "# library to convert the target variables to numpy arrays\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# library to plot classification report\n",
    "from sklearn.metrics import classification_report\n",
    "# library to import Batch Normalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# Library to import Dropout\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40298f74",
   "metadata": {},
   "source": [
    "### Q Import the dataset and answer the below question \n",
    "### What does the distribution of ‘Age’ attribute look like?\n",
    "- Right-skewed\n",
    "- Left-skewed\n",
    "- Normally Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f166bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "data = pd.read_csv('Loan_payments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158ec8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x21ea7fcffa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data=data, x='age', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4015754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219702338351359"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.age.skew() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7af2e",
   "metadata": {},
   "source": [
    "### Correct Answer: Right Skewed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df9c94",
   "metadata": {},
   "source": [
    "### Q Build a Neural Network Model on the dataset and Obtain accuracy by following the below steps:\n",
    "\n",
    "- Store the Independent and Dependent features in X and y\n",
    "- Use train_test split to split the data (80% for training and 20% for testing)\n",
    "- Convert the target feature into a NumPy array using Keras to_categorical function\n",
    "\n",
    "\n",
    "Use the below parameters mentioned and \n",
    "\n",
    "    - The number of neurons in the First and second layers is 64 and 32 respectively.\n",
    "    - Use Dropout of ratio 0.2 after second layer.\n",
    "    - Use ReLu as an Activation function in Hidden layers and Adam as an Optimizer with 1e-3 as learning rate\n",
    "    - Build the model on 20 Epochs\n",
    "\n",
    "\n",
    "- Note \n",
    "\n",
    "  - Do not use stratify sampling and Callbacks.\n",
    "  - The given dataset is scaled, so please don't scale the data again. \n",
    "  \n",
    "  \n",
    "- `>`30 and `<`50\n",
    "- `>`51 and `<`70\n",
    "- `>`70 and `<`85\n",
    "- `>`90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b8acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the Independent and Dependent features in X and y\n",
    "X = data.drop('loan_status',axis=1)\n",
    "Y = data[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a0c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test split to split the data (80% for training and 20% for testing)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8037bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target feature into a NumPy array using Keras to_categorical function\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test_cat = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34c0e795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 - 0s - loss: 68.3540 - accuracy: 0.3719 - val_loss: 38.5270 - val_accuracy: 0.6125 - 449ms/epoch - 45ms/step\n",
      "Epoch 2/20\n",
      "10/10 - 0s - loss: 43.5958 - accuracy: 0.5875 - val_loss: 25.4263 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 3/20\n",
      "10/10 - 0s - loss: 28.0714 - accuracy: 0.4563 - val_loss: 9.5784 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 4/20\n",
      "10/10 - 0s - loss: 16.2916 - accuracy: 0.4875 - val_loss: 8.6752 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 5/20\n",
      "10/10 - 0s - loss: 10.7863 - accuracy: 0.4219 - val_loss: 5.4323 - val_accuracy: 0.6000 - 32ms/epoch - 3ms/step\n",
      "Epoch 6/20\n",
      "10/10 - 0s - loss: 8.7959 - accuracy: 0.4719 - val_loss: 6.5111 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 7/20\n",
      "10/10 - 0s - loss: 6.7043 - accuracy: 0.4313 - val_loss: 2.0239 - val_accuracy: 0.5875 - 32ms/epoch - 3ms/step\n",
      "Epoch 8/20\n",
      "10/10 - 0s - loss: 4.6589 - accuracy: 0.4563 - val_loss: 2.3471 - val_accuracy: 0.6000 - 32ms/epoch - 3ms/step\n",
      "Epoch 9/20\n",
      "10/10 - 0s - loss: 2.7296 - accuracy: 0.4250 - val_loss: 1.3353 - val_accuracy: 0.6000 - 32ms/epoch - 3ms/step\n",
      "Epoch 10/20\n",
      "10/10 - 0s - loss: 1.8933 - accuracy: 0.4531 - val_loss: 1.2352 - val_accuracy: 0.5875 - 40ms/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "10/10 - 0s - loss: 1.4718 - accuracy: 0.4250 - val_loss: 1.0817 - val_accuracy: 0.5500 - 32ms/epoch - 3ms/step\n",
      "Epoch 12/20\n",
      "10/10 - 0s - loss: 1.2313 - accuracy: 0.4906 - val_loss: 0.9818 - val_accuracy: 0.5875 - 32ms/epoch - 3ms/step\n",
      "Epoch 13/20\n",
      "10/10 - 0s - loss: 1.1188 - accuracy: 0.4781 - val_loss: 0.9581 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "10/10 - 0s - loss: 1.0054 - accuracy: 0.5969 - val_loss: 0.9783 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 15/20\n",
      "10/10 - 0s - loss: 0.9836 - accuracy: 0.5562 - val_loss: 0.9657 - val_accuracy: 0.6125 - 43ms/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "10/10 - 0s - loss: 0.9713 - accuracy: 0.6219 - val_loss: 0.9767 - val_accuracy: 0.6125 - 25ms/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "10/10 - 0s - loss: 0.9644 - accuracy: 0.6000 - val_loss: 0.9431 - val_accuracy: 0.6125 - 27ms/epoch - 3ms/step\n",
      "Epoch 18/20\n",
      "10/10 - 0s - loss: 0.9532 - accuracy: 0.6219 - val_loss: 0.9687 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 19/20\n",
      "10/10 - 0s - loss: 0.9523 - accuracy: 0.6281 - val_loss: 1.0189 - val_accuracy: 0.5875 - 32ms/epoch - 3ms/step\n",
      "Epoch 20/20\n",
      "10/10 - 0s - loss: 0.9544 - accuracy: 0.5688 - val_loss: 0.9788 - val_accuracy: 0.6125 - 29ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model = keras.Sequential()\n",
    "# Adding the input layer with 64 neurons with relu as an activation function with input shape 11\n",
    "model.add(Dense(64, activation='relu',input_shape=(11,))) \n",
    "# Adding the first hidden layer with 32 neurons with relu as an activation function\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# Adding dropout layer with ratio of 0.2 \n",
    "model.add(Dropout(0.2))\n",
    "# Defining the output layer with 3 neurons with softmax as an activation function\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Defining the Adam Optimizers\n",
    "adam = optimizers.Adam(lr=1e-3)\n",
    "# Compiling the model with categorical crossentropy as loss function with accuracy as metrics\n",
    "model.compile(loss=losses.categorical_crossentropy, optimizer=adam, metrics=['accuracy']) \n",
    "# Fitting the model on X_train and y_train with 20 epcohs with 20% of validation split\n",
    "history=model.fit(X_train, y_train, epochs=20,  validation_split=0.2,  verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac10f22",
   "metadata": {},
   "source": [
    "### Correct Answer:  >51 and <70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c44399",
   "metadata": {},
   "source": [
    "### Q Build a model on the data using the below hyperparameters and find the f1-score of 0th class .\n",
    "\n",
    "- The number of neurons in the first, second, third, and fourth layers should be 256,124,64 and 32 respectively.\n",
    "- Use the BatchNormalization after second layer.\n",
    "- Use ReLu as an Activation function in Hidden layers and RMSprop as Optimizer with 1e-3 as learning rate\n",
    "- Build the model on 50 Epochs\n",
    "\n",
    "\n",
    "\n",
    "- Note\n",
    "\n",
    "    - Do not use stratify sampling and Callbacks.\n",
    "    - The given dataset is scaled, so please don't scale the data again.\n",
    " \n",
    " \n",
    "- 0.51 - 0.55\n",
    "- 0.71 - 0.80\n",
    "- 0.60 - 0.70\n",
    "- 0.35 - 0.50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "890657ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 - 1s - loss: 1.0853 - accuracy: 0.4969 - val_loss: 17.2261 - val_accuracy: 0.6125 - 649ms/epoch - 65ms/step\n",
      "Epoch 2/50\n",
      "10/10 - 0s - loss: 0.9499 - accuracy: 0.6250 - val_loss: 13.2569 - val_accuracy: 0.6125 - 53ms/epoch - 5ms/step\n",
      "Epoch 3/50\n",
      "10/10 - 0s - loss: 0.9408 - accuracy: 0.6250 - val_loss: 8.8035 - val_accuracy: 0.6125 - 43ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "10/10 - 0s - loss: 0.9483 - accuracy: 0.6250 - val_loss: 6.5334 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "10/10 - 0s - loss: 0.9416 - accuracy: 0.6250 - val_loss: 5.3939 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "10/10 - 0s - loss: 0.9281 - accuracy: 0.6250 - val_loss: 4.7476 - val_accuracy: 0.6125 - 41ms/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "10/10 - 0s - loss: 0.9396 - accuracy: 0.6250 - val_loss: 3.6360 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "10/10 - 0s - loss: 0.9450 - accuracy: 0.6250 - val_loss: 3.1617 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 9/50\n",
      "10/10 - 0s - loss: 0.9230 - accuracy: 0.6250 - val_loss: 2.3563 - val_accuracy: 0.6125 - 48ms/epoch - 5ms/step\n",
      "Epoch 10/50\n",
      "10/10 - 0s - loss: 0.9268 - accuracy: 0.6250 - val_loss: 2.1983 - val_accuracy: 0.6125 - 48ms/epoch - 5ms/step\n",
      "Epoch 11/50\n",
      "10/10 - 0s - loss: 0.9383 - accuracy: 0.6250 - val_loss: 1.3776 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 12/50\n",
      "10/10 - 0s - loss: 0.9213 - accuracy: 0.6250 - val_loss: 1.9244 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 13/50\n",
      "10/10 - 0s - loss: 0.9286 - accuracy: 0.6250 - val_loss: 1.7225 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 14/50\n",
      "10/10 - 0s - loss: 0.9434 - accuracy: 0.6250 - val_loss: 1.0956 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 15/50\n",
      "10/10 - 0s - loss: 0.9326 - accuracy: 0.6250 - val_loss: 0.9711 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "10/10 - 0s - loss: 0.9246 - accuracy: 0.6250 - val_loss: 1.0237 - val_accuracy: 0.4750 - 32ms/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "10/10 - 0s - loss: 0.9352 - accuracy: 0.6250 - val_loss: 1.0431 - val_accuracy: 0.4750 - 41ms/epoch - 4ms/step\n",
      "Epoch 18/50\n",
      "10/10 - 0s - loss: 0.9251 - accuracy: 0.6250 - val_loss: 1.0787 - val_accuracy: 0.4625 - 56ms/epoch - 6ms/step\n",
      "Epoch 19/50\n",
      "10/10 - 0s - loss: 0.9349 - accuracy: 0.6250 - val_loss: 1.1149 - val_accuracy: 0.2500 - 40ms/epoch - 4ms/step\n",
      "Epoch 20/50\n",
      "10/10 - 0s - loss: 0.9259 - accuracy: 0.6250 - val_loss: 1.0761 - val_accuracy: 0.4875 - 44ms/epoch - 4ms/step\n",
      "Epoch 21/50\n",
      "10/10 - 0s - loss: 0.9262 - accuracy: 0.6250 - val_loss: 1.7908 - val_accuracy: 0.6125 - 38ms/epoch - 4ms/step\n",
      "Epoch 22/50\n",
      "10/10 - 0s - loss: 0.9169 - accuracy: 0.6250 - val_loss: 1.0804 - val_accuracy: 0.6125 - 46ms/epoch - 5ms/step\n",
      "Epoch 23/50\n",
      "10/10 - 0s - loss: 0.9133 - accuracy: 0.6250 - val_loss: 1.3753 - val_accuracy: 0.6125 - 45ms/epoch - 4ms/step\n",
      "Epoch 24/50\n",
      "10/10 - 0s - loss: 0.9232 - accuracy: 0.6250 - val_loss: 1.4764 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 25/50\n",
      "10/10 - 0s - loss: 0.9316 - accuracy: 0.6250 - val_loss: 1.6422 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 26/50\n",
      "10/10 - 0s - loss: 0.9197 - accuracy: 0.6250 - val_loss: 1.2950 - val_accuracy: 0.4000 - 35ms/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "10/10 - 0s - loss: 0.9178 - accuracy: 0.6250 - val_loss: 0.9314 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 28/50\n",
      "10/10 - 0s - loss: 0.9272 - accuracy: 0.6250 - val_loss: 0.9473 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 29/50\n",
      "10/10 - 0s - loss: 0.9229 - accuracy: 0.6250 - val_loss: 1.1030 - val_accuracy: 0.6125 - 50ms/epoch - 5ms/step\n",
      "Epoch 30/50\n",
      "10/10 - 0s - loss: 0.9194 - accuracy: 0.6250 - val_loss: 1.2187 - val_accuracy: 0.3000 - 34ms/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "10/10 - 0s - loss: 0.9238 - accuracy: 0.6250 - val_loss: 1.3322 - val_accuracy: 0.6125 - 47ms/epoch - 5ms/step\n",
      "Epoch 32/50\n",
      "10/10 - 0s - loss: 0.9131 - accuracy: 0.6250 - val_loss: 1.3132 - val_accuracy: 0.6125 - 39ms/epoch - 4ms/step\n",
      "Epoch 33/50\n",
      "10/10 - 0s - loss: 0.9261 - accuracy: 0.6250 - val_loss: 1.6137 - val_accuracy: 0.6125 - 37ms/epoch - 4ms/step\n",
      "Epoch 34/50\n",
      "10/10 - 0s - loss: 0.9211 - accuracy: 0.6250 - val_loss: 1.6117 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "10/10 - 0s - loss: 0.9171 - accuracy: 0.6250 - val_loss: 1.6317 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "10/10 - 0s - loss: 0.9151 - accuracy: 0.6250 - val_loss: 1.5762 - val_accuracy: 0.6125 - 48ms/epoch - 5ms/step\n",
      "Epoch 37/50\n",
      "10/10 - 0s - loss: 0.9212 - accuracy: 0.6250 - val_loss: 1.7320 - val_accuracy: 0.6125 - 49ms/epoch - 5ms/step\n",
      "Epoch 38/50\n",
      "10/10 - 0s - loss: 0.9176 - accuracy: 0.6250 - val_loss: 1.9513 - val_accuracy: 0.6125 - 51ms/epoch - 5ms/step\n",
      "Epoch 39/50\n",
      "10/10 - 0s - loss: 0.9220 - accuracy: 0.6250 - val_loss: 2.1199 - val_accuracy: 0.6125 - 41ms/epoch - 4ms/step\n",
      "Epoch 40/50\n",
      "10/10 - 0s - loss: 0.9152 - accuracy: 0.6250 - val_loss: 2.4207 - val_accuracy: 0.6125 - 37ms/epoch - 4ms/step\n",
      "Epoch 41/50\n",
      "10/10 - 0s - loss: 0.9213 - accuracy: 0.6250 - val_loss: 4.5859 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "10/10 - 0s - loss: 0.9160 - accuracy: 0.6250 - val_loss: 2.1596 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 43/50\n",
      "10/10 - 0s - loss: 0.9204 - accuracy: 0.6250 - val_loss: 1.4841 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 44/50\n",
      "10/10 - 0s - loss: 0.9183 - accuracy: 0.6250 - val_loss: 1.4507 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 45/50\n",
      "10/10 - 0s - loss: 0.9115 - accuracy: 0.6250 - val_loss: 1.1315 - val_accuracy: 0.6125 - 43ms/epoch - 4ms/step\n",
      "Epoch 46/50\n",
      "10/10 - 0s - loss: 0.9183 - accuracy: 0.6250 - val_loss: 1.2029 - val_accuracy: 0.6125 - 50ms/epoch - 5ms/step\n",
      "Epoch 47/50\n",
      "10/10 - 0s - loss: 0.9297 - accuracy: 0.6250 - val_loss: 1.4231 - val_accuracy: 0.6125 - 46ms/epoch - 5ms/step\n",
      "Epoch 48/50\n",
      "10/10 - 0s - loss: 0.9189 - accuracy: 0.6250 - val_loss: 1.8122 - val_accuracy: 0.6125 - 38ms/epoch - 4ms/step\n",
      "Epoch 49/50\n",
      "10/10 - 0s - loss: 0.9156 - accuracy: 0.6250 - val_loss: 1.7068 - val_accuracy: 0.6125 - 41ms/epoch - 4ms/step\n",
      "Epoch 50/50\n",
      "10/10 - 0s - loss: 0.9145 - accuracy: 0.6250 - val_loss: 1.6337 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model_1 = keras.Sequential()\n",
    "# Adding the input layer with 256 neurons with relu as an activation function with input shape 11\n",
    "model_1.add(Dense(256, activation='relu',input_shape=(11,)))\n",
    "# Adding the first hidden layer with 124 neurons with relu as an activation function\n",
    "model_1.add(Dense(124, activation='relu'))\n",
    "# Adding Batch Normalization\n",
    "model_1.add(BatchNormalization())\n",
    "# Adding the second hidden layer with 64 neurons with relu as an activation function\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "# Adding the third hidden layer with 32 neurons with relu as an activation function\n",
    "model_1.add(Dense(32, activation='relu'))\n",
    "# Defining the output layer with 3 neurons with softmax as an activation function\n",
    "model_1.add(Dense(3, activation='softmax'))\n",
    "# Defining the RMSprop Optimizers\n",
    "RMSprop = optimizers.RMSprop(lr=1e-3)\n",
    "# Compiling the model with categorical crossentropy as loss function with accuracy as metrics\n",
    "model_1.compile(loss=losses.categorical_crossentropy, optimizer=RMSprop, metrics=['accuracy']) \n",
    "# Fitting the model on X_train and y_train with 50 epcohs with 20% of validation split\n",
    "history_1=model_1.fit(X_train, y_train, validation_split=0.2, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a0c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on Test data \n",
    "y_pred=model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9522a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the argmax function\n",
    "y_pred_final=[]\n",
    "for i in y_pred:\n",
    "    y_pred_final.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3df7d23c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68        51\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.51       100\n",
      "   macro avg       0.17      0.33      0.23       100\n",
      "weighted avg       0.26      0.51      0.34       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report \n",
    "print(classification_report(y_test,y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9982281",
   "metadata": {},
   "source": [
    "### Correct Answer:  0.60 - 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c389d",
   "metadata": {},
   "source": [
    "### Q Build a model on the data using the below hyperparameters and find the precision of 0th class .\n",
    "\n",
    "- The number of neurons in the first, second, third, and fourth layers should be 128,64,64 and 32 respectively.\n",
    "- Use the Dropout of ratio 0.3 after second layer and BatchNormation after third layer. \n",
    "- Use ReLu as an Activation function in Hidden layers and Adam as Optimizer with 1e-3 as learning rate\n",
    "- Build the model on 100 Epochs\n",
    "\n",
    "\n",
    "- Note \n",
    "\n",
    "   - Do not use stratify sampling and Callbacks.\n",
    "   - The given dataset is scaled, so please don't scale the data again.\n",
    "\n",
    "- 0.20 - 0.30 \n",
    "- 0.31 - 0.60 \n",
    "- 0.61 - 0.75\n",
    "- `>`0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f30b7735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 - 1s - loss: 1.3490 - accuracy: 0.4062 - val_loss: 3.3828 - val_accuracy: 0.6125 - 501ms/epoch - 167ms/step\n",
      "Epoch 2/100\n",
      "3/3 - 0s - loss: 1.3699 - accuracy: 0.4125 - val_loss: 2.2976 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "3/3 - 0s - loss: 1.1489 - accuracy: 0.5375 - val_loss: 1.8980 - val_accuracy: 0.4125 - 32ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "3/3 - 0s - loss: 1.1693 - accuracy: 0.5031 - val_loss: 1.7188 - val_accuracy: 0.2500 - 28ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "3/3 - 0s - loss: 1.0971 - accuracy: 0.5375 - val_loss: 1.6260 - val_accuracy: 0.2500 - 24ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "3/3 - 0s - loss: 1.1431 - accuracy: 0.5437 - val_loss: 1.5548 - val_accuracy: 0.2500 - 25ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "3/3 - 0s - loss: 1.0899 - accuracy: 0.5656 - val_loss: 1.5874 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "3/3 - 0s - loss: 1.0880 - accuracy: 0.5719 - val_loss: 1.6768 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "3/3 - 0s - loss: 1.0362 - accuracy: 0.6031 - val_loss: 1.6629 - val_accuracy: 0.2500 - 35ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "3/3 - 0s - loss: 1.0728 - accuracy: 0.5844 - val_loss: 1.5773 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "3/3 - 0s - loss: 1.0581 - accuracy: 0.5938 - val_loss: 1.4604 - val_accuracy: 0.2500 - 30ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "3/3 - 0s - loss: 1.0462 - accuracy: 0.5781 - val_loss: 1.3161 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "3/3 - 0s - loss: 0.9826 - accuracy: 0.5938 - val_loss: 1.1895 - val_accuracy: 0.2500 - 33ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "3/3 - 0s - loss: 0.9987 - accuracy: 0.5938 - val_loss: 1.1113 - val_accuracy: 0.2875 - 25ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "3/3 - 0s - loss: 1.0260 - accuracy: 0.5938 - val_loss: 1.0382 - val_accuracy: 0.4000 - 24ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "3/3 - 0s - loss: 1.0054 - accuracy: 0.6125 - val_loss: 0.9883 - val_accuracy: 0.6250 - 32ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "3/3 - 0s - loss: 0.9965 - accuracy: 0.6062 - val_loss: 0.9551 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "3/3 - 0s - loss: 0.9978 - accuracy: 0.6062 - val_loss: 0.9390 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "3/3 - 0s - loss: 0.9821 - accuracy: 0.6000 - val_loss: 0.9324 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "3/3 - 0s - loss: 1.0037 - accuracy: 0.5969 - val_loss: 0.9279 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "3/3 - 0s - loss: 0.9646 - accuracy: 0.6156 - val_loss: 0.9275 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "3/3 - 0s - loss: 0.9772 - accuracy: 0.5969 - val_loss: 0.9255 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "3/3 - 0s - loss: 0.9643 - accuracy: 0.6094 - val_loss: 0.9237 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "3/3 - 0s - loss: 0.9745 - accuracy: 0.6062 - val_loss: 0.9233 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "3/3 - 0s - loss: 0.9863 - accuracy: 0.6062 - val_loss: 0.9226 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "3/3 - 0s - loss: 0.9944 - accuracy: 0.5906 - val_loss: 0.9210 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "3/3 - 0s - loss: 0.9686 - accuracy: 0.6219 - val_loss: 0.9206 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "3/3 - 0s - loss: 0.9725 - accuracy: 0.6125 - val_loss: 0.9200 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "3/3 - 0s - loss: 0.9748 - accuracy: 0.6031 - val_loss: 0.9194 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "3/3 - 0s - loss: 0.9809 - accuracy: 0.6031 - val_loss: 0.9194 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "3/3 - 0s - loss: 0.9728 - accuracy: 0.6094 - val_loss: 0.9195 - val_accuracy: 0.6125 - 27ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "3/3 - 0s - loss: 0.9259 - accuracy: 0.6250 - val_loss: 0.9210 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "3/3 - 0s - loss: 0.9874 - accuracy: 0.5969 - val_loss: 0.9274 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "3/3 - 0s - loss: 0.9480 - accuracy: 0.6031 - val_loss: 0.9377 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "3/3 - 0s - loss: 0.9707 - accuracy: 0.6125 - val_loss: 0.9398 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "3/3 - 0s - loss: 0.9447 - accuracy: 0.6313 - val_loss: 0.9374 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "3/3 - 0s - loss: 0.9506 - accuracy: 0.6281 - val_loss: 0.9330 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "3/3 - 0s - loss: 0.9866 - accuracy: 0.6000 - val_loss: 0.9304 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "3/3 - 0s - loss: 0.9431 - accuracy: 0.6313 - val_loss: 0.9338 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "3/3 - 0s - loss: 0.9604 - accuracy: 0.6250 - val_loss: 0.9323 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "3/3 - 0s - loss: 0.9314 - accuracy: 0.6250 - val_loss: 0.9295 - val_accuracy: 0.6125 - 23ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "3/3 - 0s - loss: 0.9663 - accuracy: 0.6187 - val_loss: 0.9256 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "3/3 - 0s - loss: 0.9310 - accuracy: 0.6125 - val_loss: 0.9225 - val_accuracy: 0.6125 - 28ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "3/3 - 0s - loss: 0.9643 - accuracy: 0.6094 - val_loss: 0.9220 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "3/3 - 0s - loss: 0.9561 - accuracy: 0.5938 - val_loss: 0.9238 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "3/3 - 0s - loss: 0.9477 - accuracy: 0.6094 - val_loss: 0.9233 - val_accuracy: 0.6125 - 17ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "3/3 - 0s - loss: 0.9677 - accuracy: 0.6031 - val_loss: 0.9223 - val_accuracy: 0.6125 - 19ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "3/3 - 0s - loss: 0.9314 - accuracy: 0.6250 - val_loss: 0.9212 - val_accuracy: 0.6125 - 23ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "3/3 - 0s - loss: 0.9340 - accuracy: 0.6250 - val_loss: 0.9208 - val_accuracy: 0.6125 - 27ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "3/3 - 0s - loss: 0.9652 - accuracy: 0.6156 - val_loss: 0.9220 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "3/3 - 0s - loss: 0.9486 - accuracy: 0.6062 - val_loss: 0.9232 - val_accuracy: 0.6125 - 34ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "3/3 - 0s - loss: 0.9362 - accuracy: 0.6187 - val_loss: 0.9234 - val_accuracy: 0.6125 - 26ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "3/3 - 0s - loss: 0.9484 - accuracy: 0.6219 - val_loss: 0.9236 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "3/3 - 0s - loss: 0.9075 - accuracy: 0.6313 - val_loss: 0.9239 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "3/3 - 0s - loss: 0.9276 - accuracy: 0.6219 - val_loss: 0.9241 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "3/3 - 0s - loss: 0.9833 - accuracy: 0.6125 - val_loss: 0.9246 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "3/3 - 0s - loss: 0.9723 - accuracy: 0.6187 - val_loss: 0.9261 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "3/3 - 0s - loss: 0.9620 - accuracy: 0.6187 - val_loss: 0.9295 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "3/3 - 0s - loss: 0.9323 - accuracy: 0.6250 - val_loss: 0.9316 - val_accuracy: 0.6125 - 22ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "3/3 - 0s - loss: 0.9614 - accuracy: 0.6219 - val_loss: 0.9370 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "3/3 - 0s - loss: 0.9670 - accuracy: 0.6219 - val_loss: 0.9438 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "3/3 - 0s - loss: 0.9348 - accuracy: 0.6250 - val_loss: 0.9519 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "3/3 - 0s - loss: 0.9504 - accuracy: 0.6156 - val_loss: 0.9550 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "3/3 - 0s - loss: 0.9431 - accuracy: 0.6187 - val_loss: 0.9547 - val_accuracy: 0.6125 - 29ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "3/3 - 0s - loss: 0.9652 - accuracy: 0.6250 - val_loss: 0.9580 - val_accuracy: 0.6125 - 22ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "3/3 - 0s - loss: 0.9340 - accuracy: 0.6187 - val_loss: 0.9575 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "3/3 - 0s - loss: 0.9322 - accuracy: 0.6125 - val_loss: 0.9567 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "3/3 - 0s - loss: 0.9399 - accuracy: 0.6219 - val_loss: 0.9549 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "3/3 - 0s - loss: 0.9494 - accuracy: 0.6187 - val_loss: 0.9557 - val_accuracy: 0.6125 - 31ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "3/3 - 0s - loss: 0.9257 - accuracy: 0.6187 - val_loss: 0.9541 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "3/3 - 0s - loss: 0.9541 - accuracy: 0.6313 - val_loss: 0.9499 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "3/3 - 0s - loss: 0.9510 - accuracy: 0.6187 - val_loss: 0.9463 - val_accuracy: 0.6125 - 22ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "3/3 - 0s - loss: 0.9256 - accuracy: 0.6219 - val_loss: 0.9425 - val_accuracy: 0.6125 - 29ms/epoch - 10ms/step\n",
      "Epoch 74/100\n",
      "3/3 - 0s - loss: 0.9513 - accuracy: 0.6187 - val_loss: 0.9420 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "3/3 - 0s - loss: 0.9358 - accuracy: 0.6219 - val_loss: 0.9412 - val_accuracy: 0.6125 - 18ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "3/3 - 0s - loss: 0.9316 - accuracy: 0.6281 - val_loss: 0.9410 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "3/3 - 0s - loss: 0.9291 - accuracy: 0.6250 - val_loss: 0.9410 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "3/3 - 0s - loss: 0.9070 - accuracy: 0.6250 - val_loss: 0.9418 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "3/3 - 0s - loss: 0.9358 - accuracy: 0.6219 - val_loss: 0.9421 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "3/3 - 0s - loss: 0.9327 - accuracy: 0.6187 - val_loss: 0.9416 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "3/3 - 0s - loss: 0.9327 - accuracy: 0.6250 - val_loss: 0.9364 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "3/3 - 0s - loss: 0.9522 - accuracy: 0.6219 - val_loss: 0.9326 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "3/3 - 0s - loss: 0.9365 - accuracy: 0.6250 - val_loss: 0.9348 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "3/3 - 0s - loss: 0.9607 - accuracy: 0.6219 - val_loss: 0.9454 - val_accuracy: 0.6125 - 18ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "3/3 - 0s - loss: 0.9352 - accuracy: 0.6250 - val_loss: 0.9502 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "3/3 - 0s - loss: 0.9517 - accuracy: 0.6250 - val_loss: 0.9540 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "3/3 - 0s - loss: 0.9369 - accuracy: 0.6219 - val_loss: 0.9519 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "3/3 - 0s - loss: 0.9660 - accuracy: 0.6156 - val_loss: 0.9432 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "3/3 - 0s - loss: 0.9428 - accuracy: 0.6250 - val_loss: 0.9365 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "3/3 - 0s - loss: 0.9572 - accuracy: 0.6250 - val_loss: 0.9310 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "3/3 - 0s - loss: 0.9478 - accuracy: 0.6187 - val_loss: 0.9288 - val_accuracy: 0.6125 - 28ms/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "3/3 - 0s - loss: 0.9422 - accuracy: 0.6250 - val_loss: 0.9274 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "3/3 - 0s - loss: 0.9446 - accuracy: 0.6219 - val_loss: 0.9282 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "3/3 - 0s - loss: 0.9264 - accuracy: 0.6219 - val_loss: 0.9310 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "3/3 - 0s - loss: 0.9354 - accuracy: 0.6250 - val_loss: 0.9350 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "3/3 - 0s - loss: 0.9371 - accuracy: 0.6219 - val_loss: 0.9399 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "3/3 - 0s - loss: 0.9390 - accuracy: 0.6219 - val_loss: 0.9436 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "3/3 - 0s - loss: 0.9346 - accuracy: 0.6219 - val_loss: 0.9454 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "3/3 - 0s - loss: 0.9184 - accuracy: 0.6281 - val_loss: 0.9434 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "3/3 - 0s - loss: 0.9348 - accuracy: 0.6250 - val_loss: 0.9432 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model_2 = keras.Sequential()\n",
    "# Adding the input layer with 128 neurons with relu as an activation function with input shape 11\n",
    "model_2.add(Dense(128, activation='relu',kernel_initializer='he_uniform',input_shape=(11,)))\n",
    "# Adding the first hidden layer with 124 neurons with relu as an activation function\n",
    "model_2.add(Dense(64, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Adding Dropout layer with a ratio of 0.3\n",
    "model_2.add(Dropout(0.3))\n",
    "# Adding the second hidden layer with 64 neurons with relu as an activation function\n",
    "model_2.add(Dense(64, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Applying Batch Normalization\n",
    "model_2.add(BatchNormalization())\n",
    "# Adding the third hidden layer with 64 neurons with relu as an activation function\n",
    "model_2.add(Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Defining the output layer with 3 neurons with softmax as an activation function\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "# Defining the Adam Optimizers\n",
    "adam = optimizers.Adam(lr=1e-3)\n",
    "# Compiling the model with categorical crossentropy as loss function with accuracy as metrics\n",
    "model_2.compile(loss=losses.categorical_crossentropy, optimizer=adam, metrics=['accuracy']) \n",
    "# Fitting the model on X_train and y_train with 100 epcohs with 20% of validation split\n",
    "history_2=model_2.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02950bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test data\n",
    "y_pred_2=model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f3abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying argmax function\n",
    "y_pred_final_2=[]\n",
    "for i in y_pred_2:\n",
    "    y_pred_final_2.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b38dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68        51\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.51       100\n",
      "   macro avg       0.17      0.33      0.23       100\n",
      "weighted avg       0.26      0.51      0.34       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test,y_pred_final_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955873cb",
   "metadata": {},
   "source": [
    "### Correct Answer: 0.31 - 0.60 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
