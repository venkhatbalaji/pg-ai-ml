{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35e39bb",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "This data set includes customers who have paid off their loans, who have been past due and put into collection without paying back their loan and interests, and who have paid off only after they were put in the collection. The financial product is a bullet loan that customers should pay off all of their loan debt in just one time by the end of the term, instead of an installment schedule. Of course, they could pay off earlier than their pay schedule.\n",
    "\n",
    "### Attribute information:\n",
    "\n",
    "- Loan_status: Whether a loan is paid off, in the collection, new customer yet to pay off, or paid off after the collection efforts\n",
    "\n",
    "- Principal: Basic principal loan amount at the origination\n",
    "\n",
    "- terms: Can be weekly (7 days), biweekly, and monthly payoff schedule\n",
    "\n",
    "- Age, education, gender: A customer’s basic demographic information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfeb36",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e192ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Library to encode the variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " # Library to split data\n",
    "from sklearn.model_selection import train_test_split  \n",
    "# library to import different optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "# Library to import different loss functions \n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Library to avoid the warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# importing keras library\n",
    "from tensorflow import keras\n",
    "# library to convert the target variables to numpy arrays\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# library to plot classification report\n",
    "from sklearn.metrics import classification_report\n",
    "# library to import Batch Normalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# Library to import Dropout\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40298f74",
   "metadata": {},
   "source": [
    "### Q Import the dataset and answer the below question \n",
    "### What does the distribution of ‘Age’ attribute look like?\n",
    "- Right-skewed\n",
    "- Left-skewed\n",
    "- Normally Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f166bbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Loan_payments_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# importing the data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoan_payments_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Loan_payments_data.csv'"
     ]
    }
   ],
   "source": [
    "# importing the data\n",
    "data = pd.read_csv('Loan_payments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ec8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=data, x='age', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4015754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219702338351359"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.age.skew() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7af2e",
   "metadata": {},
   "source": [
    "### Correct Answer: Right Skewed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df9c94",
   "metadata": {},
   "source": [
    "### Q Build a Neural Network Model on the dataset and Obtain accuracy by following the below steps:\n",
    "\n",
    "- Store the Independent and Dependent features in X and y\n",
    "- Use train_test split to split the data (80% for training and 20% for testing)\n",
    "- Convert the target feature into a NumPy array using Keras to_categorical function\n",
    "\n",
    "\n",
    "Use the below parameters mentioned and \n",
    "\n",
    "    - The number of neurons in the First and second layers is 64 and 32 respectively.\n",
    "    - Use Dropout of ratio 0.2 after second layer.\n",
    "    - Use ReLu as an Activation function in Hidden layers and Adam as an Optimizer with 1e-3 as learning rate\n",
    "    - Build the model on 20 Epochs\n",
    "\n",
    "\n",
    "- Note \n",
    "\n",
    "  - Do not use stratify sampling and Callbacks.\n",
    "  - The given dataset is scaled, so please don't scale the data again. \n",
    "  \n",
    "  \n",
    "- `>`30 and `<`50\n",
    "- `>`51 and `<`70\n",
    "- `>`70 and `<`85\n",
    "- `>`90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b8acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the Independent and Dependent features in X and y\n",
    "X = data.drop('loan_status',axis=1)\n",
    "Y = data[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a0c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test split to split the data (80% for training and 20% for testing)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8037bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target feature into a NumPy array using Keras to_categorical function\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test_cat = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34c0e795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 - 0s - loss: 68.3540 - accuracy: 0.3719 - val_loss: 38.5270 - val_accuracy: 0.6125 - 449ms/epoch - 45ms/step\n",
      "Epoch 2/20\n",
      "10/10 - 0s - loss: 43.5958 - accuracy: 0.5875 - val_loss: 25.4263 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 3/20\n",
      "10/10 - 0s - loss: 28.0714 - accuracy: 0.4563 - val_loss: 9.5784 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 4/20\n",
      "10/10 - 0s - loss: 16.2916 - accuracy: 0.4875 - val_loss: 8.6752 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 5/20\n",
      "10/10 - 0s - loss: 10.7863 - accuracy: 0.4219 - val_loss: 5.4323 - val_accuracy: 0.6000 - 32ms/epoch - 3ms/step\n",
      "Epoch 6/20\n",
      "10/10 - 0s - loss: 8.7959 - accuracy: 0.4719 - val_loss: 6.5111 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 7/20\n",
      "10/10 - 0s - loss: 6.7043 - accuracy: 0.4313 - val_loss: 2.0239 - val_accuracy: 0.5875 - 32ms/epoch - 3ms/step\n",
      "Epoch 8/20\n",
      "10/10 - 0s - loss: 4.6589 - accuracy: 0.4563 - val_loss: 2.3471 - val_accuracy: 0.6000 - 32ms/epoch - 3ms/step\n",
      "Epoch 9/20\n",
      "10/10 - 0s - loss: 2.7296 - accuracy: 0.4250 - val_loss: 1.3353 - val_accuracy: 0.6000 - 32ms/epoch - 3ms/step\n",
      "Epoch 10/20\n",
      "10/10 - 0s - loss: 1.8933 - accuracy: 0.4531 - val_loss: 1.2352 - val_accuracy: 0.5875 - 40ms/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "10/10 - 0s - loss: 1.4718 - accuracy: 0.4250 - val_loss: 1.0817 - val_accuracy: 0.5500 - 32ms/epoch - 3ms/step\n",
      "Epoch 12/20\n",
      "10/10 - 0s - loss: 1.2313 - accuracy: 0.4906 - val_loss: 0.9818 - val_accuracy: 0.5875 - 32ms/epoch - 3ms/step\n",
      "Epoch 13/20\n",
      "10/10 - 0s - loss: 1.1188 - accuracy: 0.4781 - val_loss: 0.9581 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "10/10 - 0s - loss: 1.0054 - accuracy: 0.5969 - val_loss: 0.9783 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 15/20\n",
      "10/10 - 0s - loss: 0.9836 - accuracy: 0.5562 - val_loss: 0.9657 - val_accuracy: 0.6125 - 43ms/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "10/10 - 0s - loss: 0.9713 - accuracy: 0.6219 - val_loss: 0.9767 - val_accuracy: 0.6125 - 25ms/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "10/10 - 0s - loss: 0.9644 - accuracy: 0.6000 - val_loss: 0.9431 - val_accuracy: 0.6125 - 27ms/epoch - 3ms/step\n",
      "Epoch 18/20\n",
      "10/10 - 0s - loss: 0.9532 - accuracy: 0.6219 - val_loss: 0.9687 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 19/20\n",
      "10/10 - 0s - loss: 0.9523 - accuracy: 0.6281 - val_loss: 1.0189 - val_accuracy: 0.5875 - 32ms/epoch - 3ms/step\n",
      "Epoch 20/20\n",
      "10/10 - 0s - loss: 0.9544 - accuracy: 0.5688 - val_loss: 0.9788 - val_accuracy: 0.6125 - 29ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model = keras.Sequential()\n",
    "# Adding the input layer with 64 neurons with relu as an activation function with input shape 11\n",
    "model.add(Dense(64, activation='relu',input_shape=(11,))) \n",
    "# Adding the first hidden layer with 32 neurons with relu as an activation function\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# Adding dropout layer with ratio of 0.2 \n",
    "model.add(Dropout(0.2))\n",
    "# Defining the output layer with 3 neurons with softmax as an activation function\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Defining the Adam Optimizers\n",
    "adam = optimizers.Adam(lr=1e-3)\n",
    "# Compiling the model with categorical crossentropy as loss function with accuracy as metrics\n",
    "model.compile(loss=losses.categorical_crossentropy, optimizer=adam, metrics=['accuracy']) \n",
    "# Fitting the model on X_train and y_train with 20 epcohs with 20% of validation split\n",
    "history=model.fit(X_train, y_train, epochs=20,  validation_split=0.2,  verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac10f22",
   "metadata": {},
   "source": [
    "### Correct Answer:  >51 and <70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c44399",
   "metadata": {},
   "source": [
    "### Q Build a model on the data using the below hyperparameters and find the f1-score of 0th class .\n",
    "\n",
    "- The number of neurons in the first, second, third, and fourth layers should be 256,124,64 and 32 respectively.\n",
    "- Use the BatchNormalization after second layer.\n",
    "- Use ReLu as an Activation function in Hidden layers and RMSprop as Optimizer with 1e-3 as learning rate\n",
    "- Build the model on 50 Epochs\n",
    "\n",
    "\n",
    "\n",
    "- Note\n",
    "\n",
    "    - Do not use stratify sampling and Callbacks.\n",
    "    - The given dataset is scaled, so please don't scale the data again.\n",
    " \n",
    " \n",
    "- 0.51 - 0.55\n",
    "- 0.71 - 0.80\n",
    "- 0.60 - 0.70\n",
    "- 0.35 - 0.50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "890657ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 - 1s - loss: 1.0853 - accuracy: 0.4969 - val_loss: 17.2261 - val_accuracy: 0.6125 - 649ms/epoch - 65ms/step\n",
      "Epoch 2/50\n",
      "10/10 - 0s - loss: 0.9499 - accuracy: 0.6250 - val_loss: 13.2569 - val_accuracy: 0.6125 - 53ms/epoch - 5ms/step\n",
      "Epoch 3/50\n",
      "10/10 - 0s - loss: 0.9408 - accuracy: 0.6250 - val_loss: 8.8035 - val_accuracy: 0.6125 - 43ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "10/10 - 0s - loss: 0.9483 - accuracy: 0.6250 - val_loss: 6.5334 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "10/10 - 0s - loss: 0.9416 - accuracy: 0.6250 - val_loss: 5.3939 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "10/10 - 0s - loss: 0.9281 - accuracy: 0.6250 - val_loss: 4.7476 - val_accuracy: 0.6125 - 41ms/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "10/10 - 0s - loss: 0.9396 - accuracy: 0.6250 - val_loss: 3.6360 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "10/10 - 0s - loss: 0.9450 - accuracy: 0.6250 - val_loss: 3.1617 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 9/50\n",
      "10/10 - 0s - loss: 0.9230 - accuracy: 0.6250 - val_loss: 2.3563 - val_accuracy: 0.6125 - 48ms/epoch - 5ms/step\n",
      "Epoch 10/50\n",
      "10/10 - 0s - loss: 0.9268 - accuracy: 0.6250 - val_loss: 2.1983 - val_accuracy: 0.6125 - 48ms/epoch - 5ms/step\n",
      "Epoch 11/50\n",
      "10/10 - 0s - loss: 0.9383 - accuracy: 0.6250 - val_loss: 1.3776 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 12/50\n",
      "10/10 - 0s - loss: 0.9213 - accuracy: 0.6250 - val_loss: 1.9244 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 13/50\n",
      "10/10 - 0s - loss: 0.9286 - accuracy: 0.6250 - val_loss: 1.7225 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 14/50\n",
      "10/10 - 0s - loss: 0.9434 - accuracy: 0.6250 - val_loss: 1.0956 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 15/50\n",
      "10/10 - 0s - loss: 0.9326 - accuracy: 0.6250 - val_loss: 0.9711 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "10/10 - 0s - loss: 0.9246 - accuracy: 0.6250 - val_loss: 1.0237 - val_accuracy: 0.4750 - 32ms/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "10/10 - 0s - loss: 0.9352 - accuracy: 0.6250 - val_loss: 1.0431 - val_accuracy: 0.4750 - 41ms/epoch - 4ms/step\n",
      "Epoch 18/50\n",
      "10/10 - 0s - loss: 0.9251 - accuracy: 0.6250 - val_loss: 1.0787 - val_accuracy: 0.4625 - 56ms/epoch - 6ms/step\n",
      "Epoch 19/50\n",
      "10/10 - 0s - loss: 0.9349 - accuracy: 0.6250 - val_loss: 1.1149 - val_accuracy: 0.2500 - 40ms/epoch - 4ms/step\n",
      "Epoch 20/50\n",
      "10/10 - 0s - loss: 0.9259 - accuracy: 0.6250 - val_loss: 1.0761 - val_accuracy: 0.4875 - 44ms/epoch - 4ms/step\n",
      "Epoch 21/50\n",
      "10/10 - 0s - loss: 0.9262 - accuracy: 0.6250 - val_loss: 1.7908 - val_accuracy: 0.6125 - 38ms/epoch - 4ms/step\n",
      "Epoch 22/50\n",
      "10/10 - 0s - loss: 0.9169 - accuracy: 0.6250 - val_loss: 1.0804 - val_accuracy: 0.6125 - 46ms/epoch - 5ms/step\n",
      "Epoch 23/50\n",
      "10/10 - 0s - loss: 0.9133 - accuracy: 0.6250 - val_loss: 1.3753 - val_accuracy: 0.6125 - 45ms/epoch - 4ms/step\n",
      "Epoch 24/50\n",
      "10/10 - 0s - loss: 0.9232 - accuracy: 0.6250 - val_loss: 1.4764 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 25/50\n",
      "10/10 - 0s - loss: 0.9316 - accuracy: 0.6250 - val_loss: 1.6422 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 26/50\n",
      "10/10 - 0s - loss: 0.9197 - accuracy: 0.6250 - val_loss: 1.2950 - val_accuracy: 0.4000 - 35ms/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "10/10 - 0s - loss: 0.9178 - accuracy: 0.6250 - val_loss: 0.9314 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 28/50\n",
      "10/10 - 0s - loss: 0.9272 - accuracy: 0.6250 - val_loss: 0.9473 - val_accuracy: 0.6125 - 40ms/epoch - 4ms/step\n",
      "Epoch 29/50\n",
      "10/10 - 0s - loss: 0.9229 - accuracy: 0.6250 - val_loss: 1.1030 - val_accuracy: 0.6125 - 50ms/epoch - 5ms/step\n",
      "Epoch 30/50\n",
      "10/10 - 0s - loss: 0.9194 - accuracy: 0.6250 - val_loss: 1.2187 - val_accuracy: 0.3000 - 34ms/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "10/10 - 0s - loss: 0.9238 - accuracy: 0.6250 - val_loss: 1.3322 - val_accuracy: 0.6125 - 47ms/epoch - 5ms/step\n",
      "Epoch 32/50\n",
      "10/10 - 0s - loss: 0.9131 - accuracy: 0.6250 - val_loss: 1.3132 - val_accuracy: 0.6125 - 39ms/epoch - 4ms/step\n",
      "Epoch 33/50\n",
      "10/10 - 0s - loss: 0.9261 - accuracy: 0.6250 - val_loss: 1.6137 - val_accuracy: 0.6125 - 37ms/epoch - 4ms/step\n",
      "Epoch 34/50\n",
      "10/10 - 0s - loss: 0.9211 - accuracy: 0.6250 - val_loss: 1.6117 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "10/10 - 0s - loss: 0.9171 - accuracy: 0.6250 - val_loss: 1.6317 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "10/10 - 0s - loss: 0.9151 - accuracy: 0.6250 - val_loss: 1.5762 - val_accuracy: 0.6125 - 48ms/epoch - 5ms/step\n",
      "Epoch 37/50\n",
      "10/10 - 0s - loss: 0.9212 - accuracy: 0.6250 - val_loss: 1.7320 - val_accuracy: 0.6125 - 49ms/epoch - 5ms/step\n",
      "Epoch 38/50\n",
      "10/10 - 0s - loss: 0.9176 - accuracy: 0.6250 - val_loss: 1.9513 - val_accuracy: 0.6125 - 51ms/epoch - 5ms/step\n",
      "Epoch 39/50\n",
      "10/10 - 0s - loss: 0.9220 - accuracy: 0.6250 - val_loss: 2.1199 - val_accuracy: 0.6125 - 41ms/epoch - 4ms/step\n",
      "Epoch 40/50\n",
      "10/10 - 0s - loss: 0.9152 - accuracy: 0.6250 - val_loss: 2.4207 - val_accuracy: 0.6125 - 37ms/epoch - 4ms/step\n",
      "Epoch 41/50\n",
      "10/10 - 0s - loss: 0.9213 - accuracy: 0.6250 - val_loss: 4.5859 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "10/10 - 0s - loss: 0.9160 - accuracy: 0.6250 - val_loss: 2.1596 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 43/50\n",
      "10/10 - 0s - loss: 0.9204 - accuracy: 0.6250 - val_loss: 1.4841 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 44/50\n",
      "10/10 - 0s - loss: 0.9183 - accuracy: 0.6250 - val_loss: 1.4507 - val_accuracy: 0.6125 - 32ms/epoch - 3ms/step\n",
      "Epoch 45/50\n",
      "10/10 - 0s - loss: 0.9115 - accuracy: 0.6250 - val_loss: 1.1315 - val_accuracy: 0.6125 - 43ms/epoch - 4ms/step\n",
      "Epoch 46/50\n",
      "10/10 - 0s - loss: 0.9183 - accuracy: 0.6250 - val_loss: 1.2029 - val_accuracy: 0.6125 - 50ms/epoch - 5ms/step\n",
      "Epoch 47/50\n",
      "10/10 - 0s - loss: 0.9297 - accuracy: 0.6250 - val_loss: 1.4231 - val_accuracy: 0.6125 - 46ms/epoch - 5ms/step\n",
      "Epoch 48/50\n",
      "10/10 - 0s - loss: 0.9189 - accuracy: 0.6250 - val_loss: 1.8122 - val_accuracy: 0.6125 - 38ms/epoch - 4ms/step\n",
      "Epoch 49/50\n",
      "10/10 - 0s - loss: 0.9156 - accuracy: 0.6250 - val_loss: 1.7068 - val_accuracy: 0.6125 - 41ms/epoch - 4ms/step\n",
      "Epoch 50/50\n",
      "10/10 - 0s - loss: 0.9145 - accuracy: 0.6250 - val_loss: 1.6337 - val_accuracy: 0.6125 - 33ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model_1 = keras.Sequential()\n",
    "# Adding the input layer with 256 neurons with relu as an activation function with input shape 11\n",
    "model_1.add(Dense(256, activation='relu',input_shape=(11,)))\n",
    "# Adding the first hidden layer with 124 neurons with relu as an activation function\n",
    "model_1.add(Dense(124, activation='relu'))\n",
    "# Adding Batch Normalization\n",
    "model_1.add(BatchNormalization())\n",
    "# Adding the second hidden layer with 64 neurons with relu as an activation function\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "# Adding the third hidden layer with 32 neurons with relu as an activation function\n",
    "model_1.add(Dense(32, activation='relu'))\n",
    "# Defining the output layer with 3 neurons with softmax as an activation function\n",
    "model_1.add(Dense(3, activation='softmax'))\n",
    "# Defining the RMSprop Optimizers\n",
    "RMSprop = optimizers.RMSprop(lr=1e-3)\n",
    "# Compiling the model with categorical crossentropy as loss function with accuracy as metrics\n",
    "model_1.compile(loss=losses.categorical_crossentropy, optimizer=RMSprop, metrics=['accuracy']) \n",
    "# Fitting the model on X_train and y_train with 50 epcohs with 20% of validation split\n",
    "history_1=model_1.fit(X_train, y_train, validation_split=0.2, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a0c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on Test data \n",
    "y_pred=model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9522a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the argmax function\n",
    "y_pred_final=[]\n",
    "for i in y_pred:\n",
    "    y_pred_final.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3df7d23c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68        51\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.51       100\n",
      "   macro avg       0.17      0.33      0.23       100\n",
      "weighted avg       0.26      0.51      0.34       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report \n",
    "print(classification_report(y_test,y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9982281",
   "metadata": {},
   "source": [
    "### Correct Answer:  0.60 - 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c389d",
   "metadata": {},
   "source": [
    "### Q Build a model on the data using the below hyperparameters and find the precision of 0th class .\n",
    "\n",
    "- The number of neurons in the first, second, third, and fourth layers should be 128,64,64 and 32 respectively.\n",
    "- Use the Dropout of ratio 0.3 after second layer and BatchNormation after third layer. \n",
    "- Use ReLu as an Activation function in Hidden layers and Adam as Optimizer with 1e-3 as learning rate\n",
    "- Build the model on 100 Epochs\n",
    "\n",
    "\n",
    "- Note \n",
    "\n",
    "   - Do not use stratify sampling and Callbacks.\n",
    "   - The given dataset is scaled, so please don't scale the data again.\n",
    "\n",
    "- 0.20 - 0.30 \n",
    "- 0.31 - 0.60 \n",
    "- 0.61 - 0.75\n",
    "- `>`0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f30b7735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 - 1s - loss: 1.3490 - accuracy: 0.4062 - val_loss: 3.3828 - val_accuracy: 0.6125 - 501ms/epoch - 167ms/step\n",
      "Epoch 2/100\n",
      "3/3 - 0s - loss: 1.3699 - accuracy: 0.4125 - val_loss: 2.2976 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "3/3 - 0s - loss: 1.1489 - accuracy: 0.5375 - val_loss: 1.8980 - val_accuracy: 0.4125 - 32ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "3/3 - 0s - loss: 1.1693 - accuracy: 0.5031 - val_loss: 1.7188 - val_accuracy: 0.2500 - 28ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "3/3 - 0s - loss: 1.0971 - accuracy: 0.5375 - val_loss: 1.6260 - val_accuracy: 0.2500 - 24ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "3/3 - 0s - loss: 1.1431 - accuracy: 0.5437 - val_loss: 1.5548 - val_accuracy: 0.2500 - 25ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "3/3 - 0s - loss: 1.0899 - accuracy: 0.5656 - val_loss: 1.5874 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "3/3 - 0s - loss: 1.0880 - accuracy: 0.5719 - val_loss: 1.6768 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "3/3 - 0s - loss: 1.0362 - accuracy: 0.6031 - val_loss: 1.6629 - val_accuracy: 0.2500 - 35ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "3/3 - 0s - loss: 1.0728 - accuracy: 0.5844 - val_loss: 1.5773 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "3/3 - 0s - loss: 1.0581 - accuracy: 0.5938 - val_loss: 1.4604 - val_accuracy: 0.2500 - 30ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "3/3 - 0s - loss: 1.0462 - accuracy: 0.5781 - val_loss: 1.3161 - val_accuracy: 0.2500 - 32ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "3/3 - 0s - loss: 0.9826 - accuracy: 0.5938 - val_loss: 1.1895 - val_accuracy: 0.2500 - 33ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "3/3 - 0s - loss: 0.9987 - accuracy: 0.5938 - val_loss: 1.1113 - val_accuracy: 0.2875 - 25ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "3/3 - 0s - loss: 1.0260 - accuracy: 0.5938 - val_loss: 1.0382 - val_accuracy: 0.4000 - 24ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "3/3 - 0s - loss: 1.0054 - accuracy: 0.6125 - val_loss: 0.9883 - val_accuracy: 0.6250 - 32ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "3/3 - 0s - loss: 0.9965 - accuracy: 0.6062 - val_loss: 0.9551 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "3/3 - 0s - loss: 0.9978 - accuracy: 0.6062 - val_loss: 0.9390 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "3/3 - 0s - loss: 0.9821 - accuracy: 0.6000 - val_loss: 0.9324 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "3/3 - 0s - loss: 1.0037 - accuracy: 0.5969 - val_loss: 0.9279 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "3/3 - 0s - loss: 0.9646 - accuracy: 0.6156 - val_loss: 0.9275 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "3/3 - 0s - loss: 0.9772 - accuracy: 0.5969 - val_loss: 0.9255 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "3/3 - 0s - loss: 0.9643 - accuracy: 0.6094 - val_loss: 0.9237 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "3/3 - 0s - loss: 0.9745 - accuracy: 0.6062 - val_loss: 0.9233 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "3/3 - 0s - loss: 0.9863 - accuracy: 0.6062 - val_loss: 0.9226 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "3/3 - 0s - loss: 0.9944 - accuracy: 0.5906 - val_loss: 0.9210 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "3/3 - 0s - loss: 0.9686 - accuracy: 0.6219 - val_loss: 0.9206 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "3/3 - 0s - loss: 0.9725 - accuracy: 0.6125 - val_loss: 0.9200 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "3/3 - 0s - loss: 0.9748 - accuracy: 0.6031 - val_loss: 0.9194 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "3/3 - 0s - loss: 0.9809 - accuracy: 0.6031 - val_loss: 0.9194 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "3/3 - 0s - loss: 0.9728 - accuracy: 0.6094 - val_loss: 0.9195 - val_accuracy: 0.6125 - 27ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "3/3 - 0s - loss: 0.9259 - accuracy: 0.6250 - val_loss: 0.9210 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "3/3 - 0s - loss: 0.9874 - accuracy: 0.5969 - val_loss: 0.9274 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "3/3 - 0s - loss: 0.9480 - accuracy: 0.6031 - val_loss: 0.9377 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "3/3 - 0s - loss: 0.9707 - accuracy: 0.6125 - val_loss: 0.9398 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "3/3 - 0s - loss: 0.9447 - accuracy: 0.6313 - val_loss: 0.9374 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "3/3 - 0s - loss: 0.9506 - accuracy: 0.6281 - val_loss: 0.9330 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "3/3 - 0s - loss: 0.9866 - accuracy: 0.6000 - val_loss: 0.9304 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "3/3 - 0s - loss: 0.9431 - accuracy: 0.6313 - val_loss: 0.9338 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "3/3 - 0s - loss: 0.9604 - accuracy: 0.6250 - val_loss: 0.9323 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "3/3 - 0s - loss: 0.9314 - accuracy: 0.6250 - val_loss: 0.9295 - val_accuracy: 0.6125 - 23ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "3/3 - 0s - loss: 0.9663 - accuracy: 0.6187 - val_loss: 0.9256 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "3/3 - 0s - loss: 0.9310 - accuracy: 0.6125 - val_loss: 0.9225 - val_accuracy: 0.6125 - 28ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "3/3 - 0s - loss: 0.9643 - accuracy: 0.6094 - val_loss: 0.9220 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "3/3 - 0s - loss: 0.9561 - accuracy: 0.5938 - val_loss: 0.9238 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "3/3 - 0s - loss: 0.9477 - accuracy: 0.6094 - val_loss: 0.9233 - val_accuracy: 0.6125 - 17ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "3/3 - 0s - loss: 0.9677 - accuracy: 0.6031 - val_loss: 0.9223 - val_accuracy: 0.6125 - 19ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "3/3 - 0s - loss: 0.9314 - accuracy: 0.6250 - val_loss: 0.9212 - val_accuracy: 0.6125 - 23ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "3/3 - 0s - loss: 0.9340 - accuracy: 0.6250 - val_loss: 0.9208 - val_accuracy: 0.6125 - 27ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "3/3 - 0s - loss: 0.9652 - accuracy: 0.6156 - val_loss: 0.9220 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "3/3 - 0s - loss: 0.9486 - accuracy: 0.6062 - val_loss: 0.9232 - val_accuracy: 0.6125 - 34ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "3/3 - 0s - loss: 0.9362 - accuracy: 0.6187 - val_loss: 0.9234 - val_accuracy: 0.6125 - 26ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "3/3 - 0s - loss: 0.9484 - accuracy: 0.6219 - val_loss: 0.9236 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "3/3 - 0s - loss: 0.9075 - accuracy: 0.6313 - val_loss: 0.9239 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "3/3 - 0s - loss: 0.9276 - accuracy: 0.6219 - val_loss: 0.9241 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "3/3 - 0s - loss: 0.9833 - accuracy: 0.6125 - val_loss: 0.9246 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "3/3 - 0s - loss: 0.9723 - accuracy: 0.6187 - val_loss: 0.9261 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "3/3 - 0s - loss: 0.9620 - accuracy: 0.6187 - val_loss: 0.9295 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "3/3 - 0s - loss: 0.9323 - accuracy: 0.6250 - val_loss: 0.9316 - val_accuracy: 0.6125 - 22ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "3/3 - 0s - loss: 0.9614 - accuracy: 0.6219 - val_loss: 0.9370 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "3/3 - 0s - loss: 0.9670 - accuracy: 0.6219 - val_loss: 0.9438 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "3/3 - 0s - loss: 0.9348 - accuracy: 0.6250 - val_loss: 0.9519 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "3/3 - 0s - loss: 0.9504 - accuracy: 0.6156 - val_loss: 0.9550 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "3/3 - 0s - loss: 0.9431 - accuracy: 0.6187 - val_loss: 0.9547 - val_accuracy: 0.6125 - 29ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "3/3 - 0s - loss: 0.9652 - accuracy: 0.6250 - val_loss: 0.9580 - val_accuracy: 0.6125 - 22ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "3/3 - 0s - loss: 0.9340 - accuracy: 0.6187 - val_loss: 0.9575 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "3/3 - 0s - loss: 0.9322 - accuracy: 0.6125 - val_loss: 0.9567 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "3/3 - 0s - loss: 0.9399 - accuracy: 0.6219 - val_loss: 0.9549 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "3/3 - 0s - loss: 0.9494 - accuracy: 0.6187 - val_loss: 0.9557 - val_accuracy: 0.6125 - 31ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "3/3 - 0s - loss: 0.9257 - accuracy: 0.6187 - val_loss: 0.9541 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "3/3 - 0s - loss: 0.9541 - accuracy: 0.6313 - val_loss: 0.9499 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "3/3 - 0s - loss: 0.9510 - accuracy: 0.6187 - val_loss: 0.9463 - val_accuracy: 0.6125 - 22ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "3/3 - 0s - loss: 0.9256 - accuracy: 0.6219 - val_loss: 0.9425 - val_accuracy: 0.6125 - 29ms/epoch - 10ms/step\n",
      "Epoch 74/100\n",
      "3/3 - 0s - loss: 0.9513 - accuracy: 0.6187 - val_loss: 0.9420 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "3/3 - 0s - loss: 0.9358 - accuracy: 0.6219 - val_loss: 0.9412 - val_accuracy: 0.6125 - 18ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "3/3 - 0s - loss: 0.9316 - accuracy: 0.6281 - val_loss: 0.9410 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "3/3 - 0s - loss: 0.9291 - accuracy: 0.6250 - val_loss: 0.9410 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "3/3 - 0s - loss: 0.9070 - accuracy: 0.6250 - val_loss: 0.9418 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "3/3 - 0s - loss: 0.9358 - accuracy: 0.6219 - val_loss: 0.9421 - val_accuracy: 0.6125 - 32ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "3/3 - 0s - loss: 0.9327 - accuracy: 0.6187 - val_loss: 0.9416 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "3/3 - 0s - loss: 0.9327 - accuracy: 0.6250 - val_loss: 0.9364 - val_accuracy: 0.6125 - 33ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "3/3 - 0s - loss: 0.9522 - accuracy: 0.6219 - val_loss: 0.9326 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "3/3 - 0s - loss: 0.9365 - accuracy: 0.6250 - val_loss: 0.9348 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "3/3 - 0s - loss: 0.9607 - accuracy: 0.6219 - val_loss: 0.9454 - val_accuracy: 0.6125 - 18ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "3/3 - 0s - loss: 0.9352 - accuracy: 0.6250 - val_loss: 0.9502 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "3/3 - 0s - loss: 0.9517 - accuracy: 0.6250 - val_loss: 0.9540 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "3/3 - 0s - loss: 0.9369 - accuracy: 0.6219 - val_loss: 0.9519 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "3/3 - 0s - loss: 0.9660 - accuracy: 0.6156 - val_loss: 0.9432 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "3/3 - 0s - loss: 0.9428 - accuracy: 0.6250 - val_loss: 0.9365 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "3/3 - 0s - loss: 0.9572 - accuracy: 0.6250 - val_loss: 0.9310 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "3/3 - 0s - loss: 0.9478 - accuracy: 0.6187 - val_loss: 0.9288 - val_accuracy: 0.6125 - 28ms/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "3/3 - 0s - loss: 0.9422 - accuracy: 0.6250 - val_loss: 0.9274 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "3/3 - 0s - loss: 0.9446 - accuracy: 0.6219 - val_loss: 0.9282 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "3/3 - 0s - loss: 0.9264 - accuracy: 0.6219 - val_loss: 0.9310 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "3/3 - 0s - loss: 0.9354 - accuracy: 0.6250 - val_loss: 0.9350 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "3/3 - 0s - loss: 0.9371 - accuracy: 0.6219 - val_loss: 0.9399 - val_accuracy: 0.6125 - 16ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "3/3 - 0s - loss: 0.9390 - accuracy: 0.6219 - val_loss: 0.9436 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "3/3 - 0s - loss: 0.9346 - accuracy: 0.6219 - val_loss: 0.9454 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "3/3 - 0s - loss: 0.9184 - accuracy: 0.6281 - val_loss: 0.9434 - val_accuracy: 0.6125 - 25ms/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "3/3 - 0s - loss: 0.9348 - accuracy: 0.6250 - val_loss: 0.9432 - val_accuracy: 0.6125 - 24ms/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model_2 = keras.Sequential()\n",
    "# Adding the input layer with 128 neurons with relu as an activation function with input shape 11\n",
    "model_2.add(Dense(128, activation='relu',kernel_initializer='he_uniform',input_shape=(11,)))\n",
    "# Adding the first hidden layer with 124 neurons with relu as an activation function\n",
    "model_2.add(Dense(64, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Adding Dropout layer with a ratio of 0.3\n",
    "model_2.add(Dropout(0.3))\n",
    "# Adding the second hidden layer with 64 neurons with relu as an activation function\n",
    "model_2.add(Dense(64, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Applying Batch Normalization\n",
    "model_2.add(BatchNormalization())\n",
    "# Adding the third hidden layer with 64 neurons with relu as an activation function\n",
    "model_2.add(Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Defining the output layer with 3 neurons with softmax as an activation function\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "# Defining the Adam Optimizers\n",
    "adam = optimizers.Adam(lr=1e-3)\n",
    "# Compiling the model with categorical crossentropy as loss function with accuracy as metrics\n",
    "model_2.compile(loss=losses.categorical_crossentropy, optimizer=adam, metrics=['accuracy']) \n",
    "# Fitting the model on X_train and y_train with 100 epcohs with 20% of validation split\n",
    "history_2=model_2.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02950bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test data\n",
    "y_pred_2=model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f3abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying argmax function\n",
    "y_pred_final_2=[]\n",
    "for i in y_pred_2:\n",
    "    y_pred_final_2.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b38dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68        51\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.51       100\n",
      "   macro avg       0.17      0.33      0.23       100\n",
      "weighted avg       0.26      0.51      0.34       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test,y_pred_final_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955873cb",
   "metadata": {},
   "source": [
    "### Correct Answer: 0.31 - 0.60 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
